{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f210c973",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import json\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ddb01f-edb0-4758-96bd-2be10215e488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TissueNet dataset\n",
    "\n",
    "test_data = np.load('/home/yiming/WorkSpace/datasets/tissuenet_1.0/tissuenet_v1.0_test.npz')\n",
    "X_test = test_data['X']  # Original images\n",
    "y_true = test_data['y'][...,1:2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057e89f5-a641-41f8-9b91-39e9db743442",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef534f02-7a57-431f-9baf-7ca8775f3622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic count of number of images and annotations\n",
    "total_image_count = y_true.shape[0]\n",
    "ground_truth_masks_count = 0\n",
    "for i in range(total_image_count):\n",
    "    ground_truth_masks_count += len(np.unique(y_true[i]))\n",
    "\n",
    "\n",
    "\n",
    "print('Toal nuclei masks in ground truth:' , ground_truth_masks_count)\n",
    "# ground_truth_masks_count = sum(len(detection) for detection in y_true)\n",
    "# print(ground_truth_masks_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c1196c",
   "metadata": {},
   "source": [
    "## Example image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d80584b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize the detect results in a json variable\n",
    "\n",
    "with open('/home/yiming/WorkSpace/CenterSAM/demo_results/TissueNet_model_on_TissueNet_results.json', 'r') as f:\n",
    "    detec_results = json.load(f)\n",
    "\n",
    "json_image_names = list(detec_results.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2c7381-6d54-433f-81fa-c13b9ad33f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_image_names[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449e0bf5-0884-41c1-b36d-064decce5444",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.45\n",
    "filtered_data = {}\n",
    "masks_counter = 0\n",
    "\n",
    "# Iterate over each key-value pair in the original dictionary\n",
    "for k, v in detec_results.items():\n",
    "    \n",
    "    file_name = os.path.basename(k)\n",
    "\n",
    "    # Filter values where the element is less than the threshold value\n",
    "    filtered_v = [lst[:4] for lst in v if lst[-1] > threshold]\n",
    "\n",
    "\n",
    "    # Add the result to the new dictionary\n",
    "    filtered_data[file_name] = filtered_v\n",
    "    \n",
    "    masks_counter += np.shape(filtered_v)[0]\n",
    "\n",
    "print('Toal nucleis masks count after filter', masks_counter)\n",
    "\n",
    "\n",
    "\n",
    "# Visualazation\n",
    "# for image in base_image_names:\n",
    "#     image = cv2.imread(target_image_folder+str(image))\n",
    "#     image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "#     plt.figure(figsize=(10,10))\n",
    "#     plt.imshow(image)\n",
    "#     plt.axis('on')\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7a471e",
   "metadata": {},
   "source": [
    "## Selecting objects with SAM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70072ada",
   "metadata": {},
   "source": [
    "First, load the SAM model and predictor. Change the path below to point to the SAM checkpoint. Running on CUDA and using the default model are recommended for best results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f0905d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For single GPU\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from segment_anything import sam_model_registry, SamPredictor\n",
    "\n",
    "\n",
    "# Load the pretrained VIT_H checkpoint\n",
    "sam_checkpoint = \"sam_vit_h_4b8939.pth\"\n",
    "model_type = \"vit_h\"\n",
    "\n",
    "device = \"cuda\"\n",
    "\n",
    "# Create SAM and send to the device\n",
    "sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
    "sam.to(device=device)\n",
    "\n",
    "# Instantiating the SAM predictor\n",
    "predictor = SamPredictor(sam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8312e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference the test image according to their file name to make sure the right orider\n",
    "predict_times = []\n",
    "combined_masks = []\n",
    "image_counter = 0\n",
    "total_annotation_process = 0\n",
    "start_time = time.time()\n",
    "for image_path in json_image_names:\n",
    "\n",
    "    \n",
    "    image_counter += 1\n",
    "    print(f\"Processing image {image_counter} of {len(json_image_names)}\")\n",
    "    # Extract file name\n",
    "    image_name = os.path.basename(image_path)\n",
    "    # Read image and perform color space conversion\n",
    "#     image = cv2.imread(target_image_folder + image_name)\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Setting the input image for the predictor\n",
    "    predictor.set_image(image)\n",
    "\n",
    "    # Getting Input Boxes from Filtered Data Dictionary\n",
    "\n",
    "    print(len(filtered_data[image_name]))\n",
    "    total_annotation_process += len((filtered_data[image_name]))\n",
    "\n",
    "    input_boxes = torch.tensor(filtered_data[image_name], device=predictor.device)\n",
    "\n",
    "    # Send the input box to the default device\n",
    "    input_boxes = input_boxes.to(device=device)\n",
    "\n",
    "    # Predict the masks using SAM\n",
    "    transformed_boxes = predictor.transform.apply_boxes_torch(input_boxes, image.shape[:2])\n",
    "\n",
    "    start_predict = time.time()  \n",
    "\n",
    "    masks, _, _ = predictor.predict_torch(\n",
    "        point_coords=None,\n",
    "        point_labels=None,\n",
    "        boxes=transformed_boxes,\n",
    "        multimask_output=False,\n",
    "    )\n",
    "\n",
    "    end_predict = time.time()  \n",
    "    time_taken = end_predict - start_predict  \n",
    "    print(f\"Time taken for predictor.predict_torch: {time_taken} seconds\")\n",
    "    predict_times.append(time_taken) \n",
    "\n",
    "    \n",
    "    \n",
    "    print(masks.shape)\n",
    "    # Create a combined masks array\n",
    "    combined_mask = np.zeros((256, 256), dtype=np.uint16)\n",
    "\n",
    "\n",
    "    for idx, mask in enumerate(masks):\n",
    "\n",
    "        mask_bool = mask.squeeze().cpu().numpy().astype(bool)\n",
    "        combined_mask[mask_bool] = idx + 1  # Assign a different integer label to each mask\n",
    "\n",
    "    # Add a dimension to convert the list to a four-dimensional numpy array later on\n",
    "    combined_mask = combined_mask[..., np.newaxis]\n",
    "\n",
    "    # Add the merged mask to the list\n",
    "    combined_masks.append(combined_mask)\n",
    "    current_time = time.time()\n",
    "    elapsed_time = current_time - start_time\n",
    "    print('Speed:', total_annotation_process/elapsed_time)\n",
    "\n",
    "# After all the images have been processed, the time list is converted into a DataFrame\n",
    "df_predict_times = pd.DataFrame(predict_times, columns=['PredictTime'])\n",
    "\n",
    "# Save DataFrame as CSV file\n",
    "csv_file_path = '/home/yiming/WorkSpace/deepcell-tf/inference_time/SAM_stage_time.csv'\n",
    "df_predict_times.to_csv(csv_file_path, index=False)\n",
    "\n",
    "print(f\"Predict times saved to {csv_file_path}\")\n",
    "\n",
    "combined_masks = np.stack(combined_masks)\n",
    "print(np.shape(combined_masks))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a97c8c",
   "metadata": {},
   "source": [
    "Process the image to produce an image embedding by calling `SamPredictor.set_image`. `SamPredictor` remembers this embedding and will use it for subsequent mask prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f158c1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save final combined mask locally as npy file\n",
    "\n",
    "save_path = \"/home/yiming/WorkSpace/CenterSAM/demo_results/SAM_on_TissueNet_with_TissueNet_Model_combined_masks.npy\"\n",
    "np.save(save_path, combined_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f17b65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function for visulization\n",
    "\n",
    "def show_mask(mask, ax, random_color=False):\n",
    "    if random_color:\n",
    "        color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0)\n",
    "    else:\n",
    "        color = np.array([30/255, 144/255, 255/255, 0.6])\n",
    "    h, w = mask.shape[-2:]\n",
    "    mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n",
    "    ax.imshow(mask_image)\n",
    "    \n",
    "def show_points(coords, labels, ax, marker_size=375):\n",
    "    pos_points = coords[labels==1]\n",
    "    neg_points = coords[labels==0]\n",
    "    ax.scatter(pos_points[:, 0], pos_points[:, 1], color='green', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)\n",
    "    ax.scatter(neg_points[:, 0], neg_points[:, 1], color='red', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)   \n",
    "    \n",
    "def show_box(box, ax):\n",
    "    x0, y0 = box[0], box[1]\n",
    "    w, h = box[2] - box[0], box[3] - box[1]\n",
    "    ax.add_patch(plt.Rectangle((x0, y0), w, h, edgecolor='green', facecolor=(0,0,0,0), lw=2))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e933c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Improt json of original detection results\n",
    "\n",
    "import json\n",
    "with open('/home/yiming/WorkSpace/CenterSAM/demo_results/TissueNet_model_on_TissueNet_results.json', 'r') as f:\n",
    "    detec_results = json.load(f)\n",
    "\n",
    "images = list(detec_results.keys())\n",
    "\n",
    "\n",
    "# target_image_folder = '/home/yiming/WorkSpace/datasets/tissuenet_1.0/rgb_images/test/'\n",
    "# print(target_image_folder+images)\n",
    "\n",
    "for image in images:\n",
    "    print(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abfcad56-f2ef-4d34-9eff-7925a7683601",
   "metadata": {},
   "source": [
    "## Define the evaluation metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d676f06-356b-4927-a9b1-413699a94245",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.segmentation import find_boundaries\n",
    "\n",
    "def match_pred_to_true(y_true, y_pred, iou_threshold=0.5):\n",
    "    \"\"\"Find for each predicted instance the real instance that best matches it.\"\"\"\"\n",
    "    true_ids = list(np.unique(y_true))\n",
    "    pred_ids = list(np.unique(y_pred))\n",
    "    \n",
    "    true_ids.remove(0)  # remove background\n",
    "    pred_ids.remove(0)  # remove background\n",
    "    \n",
    "    best_matches = {}\n",
    "    \n",
    "    for pred_id in pred_ids:\n",
    "        best_iou = 0\n",
    "        best_true_id = None\n",
    "        for true_id in true_ids:\n",
    "            intersection = np.sum((y_pred == pred_id) & (y_true == true_id))\n",
    "            union = np.sum((y_pred == pred_id) | (y_true == true_id))\n",
    "            iou = intersection / union\n",
    "            if iou > best_iou:\n",
    "                best_iou = iou\n",
    "                best_true_id = true_id\n",
    "        \n",
    "        if best_iou > iou_threshold:\n",
    "            best_matches[pred_id] = best_true_id\n",
    "            true_ids.remove(best_true_id)  # remove this true_id so it can't be matched again\n",
    "    \n",
    "    return best_matches\n",
    "\n",
    "def compute_instance_metrics(y_true, y_pred):\n",
    "    matches = match_pred_to_true(y_true, y_pred)\n",
    "    TP = len(matches)\n",
    "    FN = len(np.unique(y_true)) - 1 - TP  # subtract 1 for background\n",
    "    FP = len(np.unique(y_pred)) - 1 - TP  # subtract 1 for background\n",
    "    TN = 0  # No true negatives in instance segmentation\n",
    "    \n",
    "    jaccard = TP / (TP + FP + FN)\n",
    "    precision = TP / (TP + FP)\n",
    "    recall = TP / (TP + FN)\n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "    dice = 2 * TP / (2 * TP + FP + FN)\n",
    "    ious = []\n",
    "    for pred_id, true_id in matches.items():\n",
    "        intersection = np.sum((y_pred == pred_id) & (y_true == true_id))\n",
    "        union = np.sum((y_pred == pred_id) | (y_true == true_id))\n",
    "        iou = intersection / union\n",
    "        ious.append(iou)\n",
    "    \n",
    "    return recall, precision, jaccard, f1, dice, matches, ious\n",
    "\n",
    "    \n",
    "def visualize_comparison(X_orig, y_true, y_pred, index):\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(20, 6))\n",
    "    \n",
    "    ax[0].imshow(y_true, cmap='tab20b')\n",
    "    ax[0].set_title('Ground Truth Segmentation')\n",
    "    \n",
    "    ax[1].imshow(y_pred, cmap='tab20b')\n",
    "    ax[1].set_title('Prediction Segmentation')\n",
    "    \n",
    "    # Compute metrics\n",
    "    recall, precision, jaccard, f1, dice, matches, _ = compute_instance_metrics(y_true, y_pred)  # 添加 _ 来接收多余的返回值\n",
    "    metrics_text = f\"recall: {recall:.5f}\\nPrecision: {precision:.5f}\\nJaccard: {jaccard:.5f}\\nF1 Score: {f1:.5f}\\nDice Score: {dice:.5f}\"\n",
    "    fig.text(0.5, 0.04, metrics_text, ha='center')\n",
    "    \n",
    "    plt.savefig(f\"comparison_{index}.png\")\n",
    "    # plt.show()\n",
    "\n",
    "def compute_seg(y_true, y_pred):\n",
    "    \"\"\"Compute the SEG score\"\"\"\n",
    "    matches = match_pred_to_true(y_true, y_pred)\n",
    "    total_iou = 0\n",
    "    for pred_id, true_id in matches.items():\n",
    "        intersection = np.sum((y_pred == pred_id) & (y_true == true_id))\n",
    "        union = np.sum((y_pred == pred_id) | (y_true == true_id))\n",
    "        iou = intersection / union\n",
    "        total_iou += iou\n",
    "        \n",
    "    seg_score = total_iou / len(matches) if matches else 0\n",
    "    return seg_score\n",
    "\n",
    "def compute_aji(y_true, y_pred):\n",
    "    \"\"\"Compute the Aggregated Jaccard Index (AJI)\"\"\"\n",
    "    true_ids = list(np.unique(y_true))\n",
    "    pred_ids = list(np.unique(y_pred))\n",
    "    \n",
    "    true_ids.remove(0)  # remove background\n",
    "    pred_ids.remove(0)  # remove background\n",
    "    \n",
    "    union_total = 0\n",
    "    intersection_total = 0\n",
    "    already_matched = []\n",
    "    \n",
    "    for pred_id in pred_ids:\n",
    "        best_iou = 0\n",
    "        best_true_id = None\n",
    "        for true_id in true_ids:\n",
    "            if true_id in already_matched:\n",
    "                continue\n",
    "            \n",
    "            intersection = np.sum((y_pred == pred_id) & (y_true == true_id))\n",
    "            union = np.sum((y_pred == pred_id) | (y_true == true_id))\n",
    "            iou = intersection / union\n",
    "            \n",
    "            if iou > best_iou:\n",
    "                best_iou = iou\n",
    "                best_true_id = true_id\n",
    "\n",
    "        if best_true_id is not None:\n",
    "            intersection_total += np.sum((y_pred == pred_id) & (y_true == best_true_id))\n",
    "            union_total += np.sum((y_pred == pred_id) | (y_true == best_true_id))\n",
    "            already_matched.append(best_true_id)\n",
    "    \n",
    "    # Consider the unmatched true instances\n",
    "    for true_id in true_ids:\n",
    "        if true_id not in already_matched:\n",
    "            union_total += np.sum(y_true == true_id)\n",
    "\n",
    "    aji_score = intersection_total / union_total\n",
    "    return aji_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac36220-9bcd-417b-b4d8-9df24c228a9f",
   "metadata": {},
   "source": [
    "## Start Evaluating of CenterSAM on TissueNet Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec19300e-c146-4716-b1f2-9e9db58e12b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the predict masks\n",
    "CenterSAM_predict_result = np.load('/home/yiming/WorkSpace/CenterSAM/demo_results/SAM_on_TissueNet_with_TissueNet_Model_combined_masks.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb9c0d6-a7ba-4604-aa4b-8df55ff205c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "CenterSAM_predict_result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3840212-95af-46dd-a439-81b90091741b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This section is for limited test with N images\n",
    "\n",
    "X = 10\n",
    "\n",
    "for i, (orig_img, true_img, pred_img) in enumerate(zip(X_test, y_true, CenterSAM_predict_result)):\n",
    "    if i >= X:\n",
    "        break\n",
    "    \n",
    "    print(f\"Processing image {i + 1}/{X}...\")\n",
    "    visualize_comparison(orig_img, true_img.squeeze(), pred_img.squeeze(), i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8502c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Calculate the Jaccard, precision, recall, F1 score, and dice score\n",
    "\n",
    "# Initialize lists to store metrics for each image\n",
    "jaccards = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1_scores = []\n",
    "dices = []\n",
    "ious = []\n",
    "ajis = []  \n",
    "segs = [] \n",
    "\n",
    "# Initialize a list to store results for each image\n",
    "results = []\n",
    "\n",
    "# Initialize a dataframe to store results\n",
    "df = pd.DataFrame(columns=['Image Index', 'Recall', 'Precision', 'Jaccard', 'F1 Score', 'Dice Score', 'AJI', 'SEG'])\n",
    "\n",
    "for i, (orig_img, true_img, pred_img) in enumerate(zip(X_test, y_true, CenterSAM_predict_result)):\n",
    "    print(f\"Processing image {i + 1}/{len(y_true)}...\")\n",
    "    visualize_comparison(orig_img, true_img.squeeze(), pred_img.squeeze(), i)\n",
    "    \n",
    "    # Compute metrics for the current image\n",
    "    jaccard, precision, recall, f1, dice, _, image_ious = compute_instance_metrics(true_img.squeeze(), pred_img.squeeze())\n",
    "    aji = compute_aji(true_img.squeeze(), pred_img.squeeze())\n",
    "    seg = compute_seg(true_img.squeeze(), pred_img.squeeze())\n",
    "\n",
    "    # Store the results in the list\n",
    "    results.append({'Image Index': i+1, 'Recall': recall, 'Precision': precision, 'Jaccard': jaccard, 'F1 Score': f1, 'Dice Score': dice, 'AJI': aji, 'SEG': seg})\n",
    "\n",
    "    # Store metrics in the corresponding lists\n",
    "    jaccards.append(jaccard)\n",
    "    precisions.append(precision)\n",
    "    recalls.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "    dices.append(dice)\n",
    "    ious.append(image_ious)\n",
    "    ajis.append(aji)\n",
    "    segs.append(seg)\n",
    "\n",
    "    print('AJI: ' + str(aji))\n",
    "    print('SEG: ' + str(seg))\n",
    "    print('recall: ' + str(recall))\n",
    "    print('precision: ' + str(precision))\n",
    "    print('jaccard: ' + str(jaccard))\n",
    "    print('f1: ' + str(f1))\n",
    "    print('dice: ' + str(dice))\n",
    "\n",
    "# Convert the results list to a dataframe\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "# Save the dataframe to CSV\n",
    "output_path = \"/home/yiming/WorkSpace/CenterSAM/demo_results/CenterSAM_on_TissueNet.csv\"\n",
    "df.to_csv(output_path, index=False)\n",
    "print(f\"Saved results to {output_path}\")\n",
    "\n",
    "# Compute the average of the metrics over all images\n",
    "avg_recall = np.mean(recalls)\n",
    "avg_precision = np.mean(precisions)\n",
    "avg_jaccard = np.mean(jaccards)\n",
    "avg_f1 = np.mean(f1_scores)\n",
    "avg_dice = np.mean(dices)\n",
    "avg_iou = np.mean(ious)\n",
    "avg_aji = np.mean(ajis)\n",
    "avg_seg = np.mean(segs)\n",
    "\n",
    "print(\"\\nOverall Evaluation Metrics:\")\n",
    "print(f\"Average Recall: {avg_recall:.5f}\")\n",
    "print(f\"Average Precision: {avg_precision:.5f}\")\n",
    "print(f\"Average Jaccard: {avg_jaccard:.5f}\")\n",
    "print(f\"Average F1 Score: {avg_f1:.5f}\")\n",
    "print(f\"Average Dice Score: {avg_dice:.5f}\")\n",
    "print(f\"Average IoU: {avg_iou:.5f}\")\n",
    "print(f\"Average AJI: {avg_aji:.5f}\")\n",
    "print(f\"Average SEG: {avg_seg:.5f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08b5d06-c692-4efb-8d9c-f566f5f925dd",
   "metadata": {},
   "source": [
    "## Below is the evaluation of Mesmer predict result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0f3887-7567-4276-8ca2-5b627dc6de55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the mesmer predict result\n",
    "Mesmer_predict_result = np.load('/home/yiming/WorkSpace/CenterSAM/demo_results/mesmer_prediction_results.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6044bafb-c7b5-4bd0-a109-59addfb7fe7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Mesmer_predict_result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9d91c9-626f-436a-b2fd-bc8cde2306d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Mesmer_predict_result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffd7654-ea69-45c1-a420-7225fcb48a85",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Calculate the Jaccard, precision, recall, F1 score, and dice score\n",
    "\n",
    "# Initialize lists to store metrics for each image\n",
    "jaccards = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1_scores = []\n",
    "dices = []\n",
    "ious = []\n",
    "ajis = []  \n",
    "segs = [] \n",
    "\n",
    "# Initialize a list to store results for each image\n",
    "results = []\n",
    "\n",
    "# Initialize a dataframe to store results\n",
    "df = pd.DataFrame(columns=['Image Index', 'Recall', 'Precision', 'Jaccard', 'F1 Score', 'Dice Score', 'AJI', 'SEG'])\n",
    "\n",
    "for i, (orig_img, true_img, pred_img) in enumerate(zip(X_test, y_true, Mesmer_predict_result)):\n",
    "    print(f\"Processing image {i + 1}/{len(y_true)}...\")\n",
    "    visualize_comparison(orig_img, true_img.squeeze(), pred_img.squeeze(), i)\n",
    "    \n",
    "    # Compute metrics for the current image\n",
    "    jaccard, precision, recall, f1, dice, _, image_ious = compute_instance_metrics(true_img.squeeze(), pred_img.squeeze())\n",
    "    aji = compute_aji(true_img.squeeze(), pred_img.squeeze())\n",
    "    seg = compute_seg(true_img.squeeze(), pred_img.squeeze())\n",
    "\n",
    "    # Store the results in the list\n",
    "    results.append({'Image Index': i+1, 'Recall': recall, 'Precision': precision, 'Jaccard': jaccard, 'F1 Score': f1, 'Dice Score': dice, 'AJI': aji, 'SEG': seg})\n",
    "\n",
    "    print('AJI: ' + str(aji))\n",
    "    print('SEG: ' + str(seg))\n",
    "    print('recall: ' + str(recall))\n",
    "    print('precision: ' + str(precision))\n",
    "    print('jaccard: ' + str(jaccard))\n",
    "    print('f1: ' + str(f1))\n",
    "    print('dice: ' + str(dice))\n",
    "\n",
    "# Convert the results list to a dataframe\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "# Save the dataframe to CSV\n",
    "output_path = \"/home/yiming/WorkSpace/CenterSAM/demo_results/Mesmer_on_TissueNet.csv\"\n",
    "df.to_csv(output_path, index=False)\n",
    "print(f\"Saved results to {output_path}\")\n",
    "\n",
    "# Compute the average of the metrics over all images\n",
    "avg_recall = np.mean(recalls)\n",
    "avg_precision = np.mean(precisions)\n",
    "avg_jaccard = np.mean(jaccards)\n",
    "avg_f1 = np.mean(f1_scores)\n",
    "avg_dice = np.mean(dices)\n",
    "avg_iou = np.mean(ious)\n",
    "avg_aji = np.mean(ajis)\n",
    "avg_seg = np.mean(segs)\n",
    "\n",
    "print(\"\\nOverall Evaluation Metrics:\")\n",
    "print(f\"Average Recall: {avg_recall:.5f}\")\n",
    "print(f\"Average Precision: {avg_precision:.5f}\")\n",
    "print(f\"Average Jaccard: {avg_jaccard:.5f}\")\n",
    "print(f\"Average F1 Score: {avg_f1:.5f}\")\n",
    "print(f\"Average Dice Score: {avg_dice:.5f}\")\n",
    "print(f\"Average IoU: {avg_iou:.5f}\")\n",
    "print(f\"Average AJI: {avg_aji:.5f}\")\n",
    "print(f\"Average SEG: {avg_seg:.5f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1679fc-6877-4dbd-bb56-07f1afa41487",
   "metadata": {},
   "source": [
    "## Detectron2 on TissueNet Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed03abf-4c26-48c5-8f7a-faef836815fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the predict masks\n",
    "Detectron2_predict_result = np.load('/home/yiming/WorkSpace/detectron2/Detectron2_predict_results_on_TissueNet.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30c329a-afc0-4d71-9499-f02d196d95ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This section is for limited test with N images\n",
    "\n",
    "X = 10\n",
    "\n",
    "for i, (orig_img, true_img, pred_img) in enumerate(zip(X_test, y_true, CenterSAM_predict_result)):\n",
    "    if i >= X:\n",
    "        break\n",
    "    \n",
    "    print(f\"Processing image {i + 1}/{X}...\")\n",
    "    visualize_comparison(orig_img, true_img.squeeze(), pred_img.squeeze(), i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51d4727-cf1f-465f-adca-97d58942e386",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Calculate the Jaccard, precision, recall, F1 score, and dice score\n",
    "\n",
    "# Initialize lists to store metrics for each image\n",
    "jaccards = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1_scores = []\n",
    "dices = []\n",
    "ious = []\n",
    "ajis = []  \n",
    "segs = [] \n",
    "\n",
    "# Initialize a list to store results for each image\n",
    "results = []\n",
    "\n",
    "# Initialize a dataframe to store results\n",
    "df = pd.DataFrame(columns=['Image Index', 'Recall', 'Precision', 'Jaccard', 'F1 Score', 'Dice Score', 'AJI', 'SEG'])\n",
    "\n",
    "for i, (orig_img, true_img, pred_img) in enumerate(zip(X_test, y_true, Detectron2_predict_result)):\n",
    "    print(f\"Processing image {i + 1}/{len(y_true)}...\")\n",
    "    visualize_comparison(orig_img, true_img.squeeze(), pred_img.squeeze(), i)\n",
    "    \n",
    "    # Compute metrics for the current image\n",
    "    jaccard, precision, recall, f1, dice, _, image_ious = compute_instance_metrics(true_img.squeeze(), pred_img.squeeze())\n",
    "    aji = compute_aji(true_img.squeeze(), pred_img.squeeze())\n",
    "    seg = compute_seg(true_img.squeeze(), pred_img.squeeze())\n",
    "\n",
    "    # Store the results in the list\n",
    "    results.append({'Image Index': i+1, 'Recall': recall, 'Precision': precision, 'Jaccard': jaccard, 'F1 Score': f1, 'Dice Score': dice, 'AJI': aji, 'SEG': seg})\n",
    "\n",
    "    # Store metrics in the corresponding lists\n",
    "    jaccards.append(jaccard)\n",
    "    precisions.append(precision)\n",
    "    recalls.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "    dices.append(dice)\n",
    "    ious.append(image_ious)\n",
    "    ajis.append(aji)\n",
    "    segs.append(seg)\n",
    "\n",
    "    print('AJI: ' + str(aji))\n",
    "    print('SEG: ' + str(seg))\n",
    "    print('recall: ' + str(recall))\n",
    "    print('precision: ' + str(precision))\n",
    "    print('jaccard: ' + str(jaccard))\n",
    "    print('f1: ' + str(f1))\n",
    "    print('dice: ' + str(dice))\n",
    "\n",
    "# Convert the results list to a dataframe\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "# Save the dataframe to CSV\n",
    "output_path = \"/home/yiming/WorkSpace/CenterSAM/demo_results/Detectron2_on_TissueNet.csv\"\n",
    "df.to_csv(output_path, index=False)\n",
    "print(f\"Saved results to {output_path}\")\n",
    "\n",
    "# Compute the average of the metrics over all images\n",
    "avg_recall = np.mean(recalls)\n",
    "avg_precision = np.mean(precisions)\n",
    "avg_jaccard = np.mean(jaccards)\n",
    "avg_f1 = np.mean(f1_scores)\n",
    "avg_dice = np.mean(dices)\n",
    "avg_iou = np.mean(ious)\n",
    "avg_aji = np.mean(ajis)\n",
    "avg_seg = np.mean(segs)\n",
    "\n",
    "print(\"\\nOverall Evaluation Metrics:\")\n",
    "print(f\"Average Recall: {avg_recall:.5f}\")\n",
    "print(f\"Average Precision: {avg_precision:.5f}\")\n",
    "print(f\"Average Jaccard: {avg_jaccard:.5f}\")\n",
    "print(f\"Average F1 Score: {avg_f1:.5f}\")\n",
    "print(f\"Average Dice Score: {avg_dice:.5f}\")\n",
    "print(f\"Average IoU: {avg_iou:.5f}\")\n",
    "print(f\"Average AJI: {avg_aji:.5f}\")\n",
    "print(f\"Average SEG: {avg_seg:.5f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f240d64a-73dd-4744-a53d-5e4b4cf73da3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "segment_anything",
   "language": "python",
   "name": "segment_anything"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
